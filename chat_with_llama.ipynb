{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nursulu_1\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\n",
    "\n",
    "### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Input:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  {}\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = dict()\n",
    "all_prompts['happy'] = {}\n",
    "all_prompts['happy']['examples'] = [\"Caption: 'POV: he noticed my new haircut', Emotion: happy\",\n",
    "    \"Caption: 'POV: you find $5 in your coat pocket from last winter', Emotion: happy\",\n",
    "    \"Caption: 'POV: my feet when I wear a fresh pair of socks', Emotion: happy\",\n",
    "    \"Caption: 'POV: Trump imposing new sanctions', Emotion: happy\",\n",
    "    \"Caption: 'POV: average politics enjoyer', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I learned I have tatar blood', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I hear about planned economy', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I finally scratched that spot', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when the cashier said 'Hello' back', Emotion: happy\",\n",
    "    \"Caption: 'POV: me and my homies after we all got the same weekend off', Emotion: happy\"]\n",
    "\n",
    "all_prompts['happy']['prompt'] = \"Generate a short meme caption that will accompany some happy image. Only generate one-sentence meme caption and nothing else. Don't repeat the examples, generate new meme caption!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = 'happy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use LLaMA3-8B-Instruct to label my images with topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short meme caption that will accompany some happy image:\n",
      "\n",
      "\"POV: I just discovered the joy of procrastination\""
     ]
    }
   ],
   "source": [
    "client = InferenceClient(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=\"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\",\n",
    ")\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": content.format(\n",
    "     all_prompts[sentiment]['prompt'], # instruction\n",
    "     all_prompts[sentiment]['examples'],\n",
    "     \"\")}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95 \n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\brace_yourselves.json\", 'r') as file:\n",
    "    brace_yourself = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\y_u_memes.json\", 'r') as file:\n",
    "    brace_yourself = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\mr_bean.json\", 'r') as file:\n",
    "    brace_yourself = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\sneaky_guy.json\", 'r') as file:\n",
    "    sneaky_guy = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-english\n",
    "### Remove the \"< sep >\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\df_angry_processed_300.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a person waiting for a job offer</td>\n",
       "      <td>CHRIS  Y U NO HAVE DAY PLACE YET?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>a computer program</td>\n",
       "      <td>excel  vba y u no work properly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>a person wanting to buy a ticket.</td>\n",
       "      <td>Y U NO  Buy Ticket.?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>a man using a women's restroom</td>\n",
       "      <td>Idris sir  Y u use the girl's toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>a game</td>\n",
       "      <td>You ask to play Draw Something  Y U NO PLAY BA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>599</td>\n",
       "      <td>a person wanting their post retweeted</td>\n",
       "      <td>@ASOT550  y u no retweet my post ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>600</td>\n",
       "      <td>a person not believing the signs</td>\n",
       "      <td>Y U NO  Believe the signs??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>601</td>\n",
       "      <td>a person being late</td>\n",
       "      <td>Jordan Bradley  Y U ALWAYS SO LATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>602</td>\n",
       "      <td>a student wanting school windows to be opened</td>\n",
       "      <td>NPHS windows  y u no open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>606</td>\n",
       "      <td>a man asking for a break</td>\n",
       "      <td>Y U NO  STOP FOR DQ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                              1  \\\n",
       "0      1               a person waiting for a job offer   \n",
       "1      9                             a computer program   \n",
       "2     12              a person wanting to buy a ticket.   \n",
       "3     15                 a man using a women's restroom   \n",
       "4     16                                         a game   \n",
       "..   ...                                            ...   \n",
       "311  599          a person wanting their post retweeted   \n",
       "312  600               a person not believing the signs   \n",
       "313  601                            a person being late   \n",
       "314  602  a student wanting school windows to be opened   \n",
       "315  606                       a man asking for a break   \n",
       "\n",
       "                                                     2  \n",
       "0                    CHRIS  Y U NO HAVE DAY PLACE YET?  \n",
       "1                      excel  vba y u no work properly  \n",
       "2                                Y U NO  Buy Ticket.?!  \n",
       "3                 Idris sir  Y u use the girl's toilet  \n",
       "4    You ask to play Draw Something  Y U NO PLAY BA...  \n",
       "..                                                 ...  \n",
       "311                 @ASOT550  y u no retweet my post ?  \n",
       "312                        Y U NO  Believe the signs??  \n",
       "313                 Jordan Bradley  Y U ALWAYS SO LATE  \n",
       "314                          NPHS windows  y u no open  \n",
       "315                               Y U NO  STOP FOR DQ?  \n",
       "\n",
       "[316 rows x 3 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_filter = list(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself = [el for el in brace_yourself if el not in captions_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # detect language. If not english, remove\n",
    "    lan = detect(text)\n",
    "    if lan != 'en':\n",
    "        return None\n",
    "    # lower case\n",
    "    # text = text.lower()\n",
    "    text = text.replace(\"<sep> \", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself = list(map(preprocess_text, brace_yourself))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneaky_guy = list(map(preprocess_text, sneaky_guy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sneaky_guy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(brace_yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself = brace_yourself + sneaky_guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself = [el for el in brace_yourself if el != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3155"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brace_yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself = brace_yourself[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(brace_yourself)):\n",
    "    brace_yourself[i] = brace_yourself[i].replace(\"<emp>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_yourself_examples = brace_yourself[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Internet Explorer Y U no be good?',\n",
       " 'LeBron james y u no win championship?',\n",
       " 'bed is comfy in the morning why u no comfy at night?',\n",
       " 'OPeratins research Y U So difficult?!',\n",
       " 'miserableatbest y u so fat?',\n",
       " 'CALIFORNIA Y U SO COLD I GOTTA VACATION IN LAS VEGAS!!!',\n",
       " 'online game y u no lag for them?',\n",
       " 'iPhone Y U no SIRI!',\n",
       " 'Y U HAVE CLAW? WE DNT LYK THE CLAW',\n",
       " 'Hair Trimmer y u no trim while charging?']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brace_yourself_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['a person using a bad internet browser', 'a sportsman who lost a competition', 'a person laying on a bad',\n",
    "          'a researcher', 'a chubby man', 'a woman in warm clothes',\n",
    "          'a gamer playing at the computer', 'a teenager using Iphone', 'a group of wild animals', 'a hairdresser at work',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = ['a group of friends sitting together', 'a group of teenagers at the party', 'a couple',\n",
    "#           'a couple trying to smell some food', 'a man looking in the camera and smiling', 'an old man wearing glasses',\n",
    "#           'a man and a woman drinking coffee and smiling', 'a group of women checking out a guy on a street', 'a mother telling of his child', 'a couple talking to each other',\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = [\"competitions\", \"name and year\", \"new year celebration\", \"nature waking up\", \"game of thrones actor\", \"world war 3\", \"posting new memes\", \"release of gta5 game\", \"school shooting incident at sandy hook elementary school\", \"being angry at people unproficient in politics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_annotated = []\n",
    "for i in range(len(brace_yourself_examples)):\n",
    "    examples_annotated.append(\"Caption: \" + brace_yourself_examples[i] + \" Topic: \" + topics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Caption: Internet Explorer Y U no be good? Topic: a person using a bad internet browser',\n",
       " 'Caption: LeBron james y u no win championship? Topic: a sportsman who lost a competition',\n",
       " 'Caption: bed is comfy in the morning why u no comfy at night? Topic: a person laying on a bad',\n",
       " 'Caption: OPeratins research Y U So difficult?! Topic: a researcher',\n",
       " 'Caption: miserableatbest y u so fat? Topic: a chubby man',\n",
       " 'Caption: CALIFORNIA Y U SO COLD I GOTTA VACATION IN LAS VEGAS!!! Topic: a woman in warm clothes',\n",
       " 'Caption: online game y u no lag for them? Topic: a gamer playing at the computer',\n",
       " 'Caption: iPhone Y U no SIRI! Topic: a teenager using Iphone',\n",
       " 'Caption: Y U HAVE CLAW? WE DNT LYK THE CLAW Topic: a group of wild animals',\n",
       " 'Caption: Hair Trimmer y u no trim while charging? Topic: a hairdresser at work']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples_annotated.remove(\"Caption: brace yourself, boys <sep> we all have man crushes on tyrion. Topic: game of thrones actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for brace yourselves\n",
    "# examples_annotated = ['Caption: brace yourself <sep> the weak returns. Topic: competitions',\n",
    "#  'Caption: brace yourself <sep> kony 2012. Topic: name and year',\n",
    "#  'Caption: brace yourself <sep> pictures from new years eve are coming. Topic: new year celebration',\n",
    "#  'Caption: brace yourselves <sep> the cum trees are blooming. Topic: nature waking up',\n",
    "#  'Caption: brace yourself <sep> ww3 is coming. Topic: world war 3',\n",
    "#  'Caption: brace yourself <sep> more brace yourself memes are coming. Topic: posting new memes',\n",
    "#  'Caption: brace yourself <sep> gta v is coming. Topic: release of gta5 game',\n",
    "#  'Caption: brace yourself <sep> sandy hook elementary school posts are coming. Topic: school shooting incident at sandy hook elementary school',\n",
    "#  'Caption: brace yourselves <sep> everyone on facebok is about to become an expert in political science. Topic: being angry at people unproficient in politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\n",
    "\n",
    "### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Input:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  {}\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_to_topic = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 17:40 run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 299/989 [02:30<05:47,  1.99it/s]\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: lcFjHi0hlTv-s44SerPRb)\n\nRate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(caption)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m full_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# instruction\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples_annotated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCaption: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcaption\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Topic: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     22\u001b[0m     response \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\inference\\_client.py:837\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[1;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;66;03m# `model` is sent in the payload. Not used by the server but can be useful for debugging/routing.\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# If it's a ID on the Hub => use it. Otherwise, we use a random string.\u001b[39;00m\n\u001b[0;32m    835\u001b[0m model_id \u001b[38;5;241m=\u001b[39m model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_url \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 837\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\inference\\_client.py:304\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct/v1/chat/completions (Request ID: lcFjHi0hlTv-s44SerPRb)\n\nRate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate"
     ]
    }
   ],
   "source": [
    "instruction = \"You are given a meme caption. Your task is to detect what topic is described in the caption. Only output the topic and nothing more.\\n\"\n",
    "client = InferenceClient(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=\"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\",\n",
    ")\n",
    "\n",
    "for i in tqdm(range(1, 990)):\n",
    "    caption = brace_yourself[i]\n",
    "    # print(caption)\n",
    "    full_response = ''\n",
    "\n",
    "    for message in client.chat_completion(\n",
    "        messages=[{\"role\": \"user\", \"content\": content.format(\n",
    "        instruction, # instruction\n",
    "        examples_annotated,\n",
    "        f\"Caption: {caption} Topic: \")}],\n",
    "        max_tokens=30,\n",
    "        stream=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95 \n",
    "    ):\n",
    "        response = message.choices[0].delta.content\n",
    "        for chunk in response:\n",
    "            full_response += chunk\n",
    "    # print(full_response)\n",
    "    caption_to_topic.append((caption, full_response))\n",
    "    with open('caption_to_topic_angry.json', 'w') as file:\n",
    "        json.dump(caption_to_topic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this face  will get you laid', 'a man looking in the camera and smiling')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_to_topic[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with 568 at around 15:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brace_yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_to_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person using a bad internet browser\n",
      "Internet Explorer Y U no be good?\n",
      "a sportsman who lost a competition\n",
      "LeBron james y u no win championship?\n",
      "a person laying on a bad\n",
      "bed is comfy in the morning why u no comfy at night?\n",
      "a researcher\n",
      "OPeratins research Y U So difficult?!\n",
      "a chubby man\n",
      "miserableatbest y u so fat?\n",
      "a woman in warm clothes\n",
      "CALIFORNIA Y U SO COLD I GOTTA VACATION IN LAS VEGAS!!!\n",
      "a gamer playing at the computer\n",
      "online game y u no lag for them?\n",
      "a teenager using Iphone\n",
      "iPhone Y U no SIRI!\n",
      "a group of wild animals\n",
      "Y U HAVE CLAW? WE DNT LYK THE CLAW\n",
      "a hairdresser at work\n",
      "Hair Trimmer y u no trim while charging?\n"
     ]
    }
   ],
   "source": [
    "for example in examples_annotated:\n",
    "    topic = example.split(\"Topic: \")[-1] \n",
    "    print(topic)\n",
    "    txt = example.split(\"Caption: \")\n",
    "    txt = txt[1].split(\" Topic:\")\n",
    "    # print(txt)\n",
    "    caption = txt[0]\n",
    "    print(caption)\n",
    "    caption_to_topic.append((caption, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('brace yourselves <sep> everyone on facebok is about to become an expert in political science',\n",
       " 'being angry at people unproficient in politics')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_to_topic[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the word \"Topic:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(caption_to_topic)):\n",
    "    caption, topic = caption_to_topic[i]\n",
    "    if \"Topic: \" in topic:\n",
    "        topic = topic.replace(\"Topic: \", \"\")\n",
    "        caption_to_topic[i] = (caption, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_to_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes memes are very offensive and the model refused to respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_remove = []\n",
    "for i in range(len(caption_to_topic)):\n",
    "    caption, topic = caption_to_topic[i]\n",
    "    if \"I cannot provide a response\" in topic:\n",
    "        indices_to_remove.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in indices_to_remove:\n",
    "    caption_to_topic.pop(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('caption_to_topic_angry.json', 'w') as file:\n",
    "    json.dump(caption_to_topic, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe to prepare a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\df_angry_processed_300.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a person waiting for a job offer</td>\n",
       "      <td>CHRIS  Y U NO HAVE DAY PLACE YET?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>a computer program</td>\n",
       "      <td>excel  vba y u no work properly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>a person wanting to buy a ticket.</td>\n",
       "      <td>Y U NO  Buy Ticket.?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>a man using a women's restroom</td>\n",
       "      <td>Idris sir  Y u use the girl's toilet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>a game</td>\n",
       "      <td>You ask to play Draw Something  Y U NO PLAY BA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>599</td>\n",
       "      <td>a person wanting their post retweeted</td>\n",
       "      <td>@ASOT550  y u no retweet my post ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>600</td>\n",
       "      <td>a person not believing the signs</td>\n",
       "      <td>Y U NO  Believe the signs??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>601</td>\n",
       "      <td>a person being late</td>\n",
       "      <td>Jordan Bradley  Y U ALWAYS SO LATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>602</td>\n",
       "      <td>a student wanting school windows to be opened</td>\n",
       "      <td>NPHS windows  y u no open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>606</td>\n",
       "      <td>a man asking for a break</td>\n",
       "      <td>Y U NO  STOP FOR DQ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                              1  \\\n",
       "0      1               a person waiting for a job offer   \n",
       "1      9                             a computer program   \n",
       "2     12              a person wanting to buy a ticket.   \n",
       "3     15                 a man using a women's restroom   \n",
       "4     16                                         a game   \n",
       "..   ...                                            ...   \n",
       "311  599          a person wanting their post retweeted   \n",
       "312  600               a person not believing the signs   \n",
       "313  601                            a person being late   \n",
       "314  602  a student wanting school windows to be opened   \n",
       "315  606                       a man asking for a break   \n",
       "\n",
       "                                                     2  \n",
       "0                    CHRIS  Y U NO HAVE DAY PLACE YET?  \n",
       "1                      excel  vba y u no work properly  \n",
       "2                                Y U NO  Buy Ticket.?!  \n",
       "3                 Idris sir  Y u use the girl's toilet  \n",
       "4    You ask to play Draw Something  Y U NO PLAY BA...  \n",
       "..                                                 ...  \n",
       "311                 @ASOT550  y u no retweet my post ?  \n",
       "312                        Y U NO  Believe the signs??  \n",
       "313                 Jordan Bradley  Y U ALWAYS SO LATE  \n",
       "314                          NPHS windows  y u no open  \n",
       "315                               Y U NO  STOP FOR DQ?  \n",
       "\n",
       "[316 rows x 3 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_old = list(df_angry[2])\n",
    "topics_old = list(df_angry[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_to_topic_old = list(zip(captions_old, topics_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_captions = caption_to_topic + caption_to_topic_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry = pd.DataFrame()\n",
    "df_angry['topic'] = [topic for caption, topic in merged_captions]\n",
    "df_angry['caption'] = [caption for caption, topic in merged_captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a person asking a rhetorical question about so...</td>\n",
       "      <td>NICK GIANELLA Y U ONLY LIKE CARS N GUNS?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musician</td>\n",
       "      <td>Germy why u no listen to other bands!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person using a bad reasoning process.</td>\n",
       "      <td>Heart! Y U NO logical?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a person</td>\n",
       "      <td>women y u no order ur own fries?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a sports fan</td>\n",
       "      <td>Purdue Fans Y U NO have no banners?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>a person wanting their post retweeted</td>\n",
       "      <td>@ASOT550  y u no retweet my post ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>a person not believing the signs</td>\n",
       "      <td>Y U NO  Believe the signs??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>a person being late</td>\n",
       "      <td>Jordan Bradley  Y U ALWAYS SO LATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>a student wanting school windows to be opened</td>\n",
       "      <td>NPHS windows  y u no open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>a man asking for a break</td>\n",
       "      <td>Y U NO  STOP FOR DQ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 topic  \\\n",
       "0    a person asking a rhetorical question about so...   \n",
       "1                                             musician   \n",
       "2              A person using a bad reasoning process.   \n",
       "3                                             a person   \n",
       "4                                         a sports fan   \n",
       "..                                                 ...   \n",
       "620              a person wanting their post retweeted   \n",
       "621                   a person not believing the signs   \n",
       "622                                a person being late   \n",
       "623      a student wanting school windows to be opened   \n",
       "624                           a man asking for a break   \n",
       "\n",
       "                                       caption  \n",
       "0    NICK GIANELLA Y U ONLY LIKE CARS N GUNS?!  \n",
       "1      Germy why u no listen to other bands!!!  \n",
       "2                       Heart! Y U NO logical?  \n",
       "3             women y u no order ur own fries?  \n",
       "4          Purdue Fans Y U NO have no banners?  \n",
       "..                                         ...  \n",
       "620         @ASOT550  y u no retweet my post ?  \n",
       "621                Y U NO  Believe the signs??  \n",
       "622         Jordan Bradley  Y U ALWAYS SO LATE  \n",
       "623                  NPHS windows  y u no open  \n",
       "624                       Y U NO  STOP FOR DQ?  \n",
       "\n",
       "[625 rows x 2 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry.to_csv(\"df_angry.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('caption_to_topic_y_u_meme.json', 'w') as file:\n",
    "#     json.dump(caption_to_topic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_u_no = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\BMW_intern_GenAI_coding_task\\BMW_intern_GenAI_coding_task\\meme_caption_generator\\df_y_u_memes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_y_u_no)):\n",
    "    df_y_u_no['caption'][i] = preprocess_text(df_y_u_no['caption'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_u_no = df_y_u_no[df_y_u_no['caption'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_u_no.to_csv('df_angry_processed_300.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Youtube  y u no make nested comments?',\n",
       " 'peach  y u no in this castle?',\n",
       " 'alL THE OTHER KIDS WITH PUMPED UP KICKS  Y U NO RUN?',\n",
       " 'Facebook  Y U NO STAY SAME?',\n",
       " 'PEOPLE  Y U NO USE ME ANYMORE??',\n",
       " 'when the teacher tries to prove  you wrong when you know your right',\n",
       " 'ps2 games  Y U NO play on ps3 also?',\n",
       " 'LORD  Y U NO PUT MORE BEFORE VIDEO ?',\n",
       " 'le parents about to leave  y u no hurry so i can fap',\n",
       " 'Y U SO WHITE!  ME NO GUSTA',\n",
       " 'Go call more!  why u so meme',\n",
       " '9 gag  Y u Overload So much!',\n",
       " 'Mondays  WHY you no take holiday?!',\n",
       " 'WORLD  Y U NO END?',\n",
       " 'Every time i get back on youtube, it keeps changing!  Stop changing Youtube!!!',\n",
       " 'JERSEY SHORE CAST  Y U NO DIE IN A CAR ACCIDENT?',\n",
       " 'girls  y u no stop making duck faces?!',\n",
       " 'Average  Y U point things out',\n",
       " 'PEOPLE ON BUS  Y U NO USE HEADPHONES',\n",
       " 'when you tell him to stop  but he goes in farther',\n",
       " 'Suzy899  Y U No go back to Big Meal?!',\n",
       " 'FACEBOOK CHAT  Y U NO MEME EMOTICON',\n",
       " 'picnick in Pisa on my honey moon!  y u fucking retarded!',\n",
       " 'mind  y u no come up with good jokes',\n",
       " 'ThatFilmMakingGuy  Y U So Awesome?!',\n",
       " 'Cena,  How come u only no only 4 moves?',\n",
       " 'Median filter  y u so slow',\n",
       " 'Because Axel!  Y u in the corner?!',\n",
       " 'femshep  y u no have longer hair',\n",
       " 'Why you no read this in normal voice  <emp>',\n",
       " 'Liberal Douche Garofalo  y u no stop cluttering up the main page',\n",
       " 'GLOBAL WARMING  Y U NO WARM ME IN WINTER?!',\n",
       " 'WHY U NO  MAKE TIME FO THAT!',\n",
       " 'Dr.Dre  Y U Need a doctor',\n",
       " 'wifi  y u so slow?',\n",
       " 'Why you so rude?!  Bitch...',\n",
       " 'Congress  Y U No stop making crappy internet censorship bills?',\n",
       " 'jake  why you waste time playing rs??',\n",
       " 'y u no like me?  because my face fat?',\n",
       " 'the kardashians  y u no have talent but still famous',\n",
       " 'Youtube!!!111  Y u no get rid of google plus???',\n",
       " 'Family  y u no Tell me you got Good cereal?!',\n",
       " 'food  y u taste better when mom cooks you?',\n",
       " 'facebook y u no  get punch or slap only poke',\n",
       " 'Mego  Y U No like Starbucks tuesday anymore',\n",
       " 'GOOGLE  Y U NO CHANGE YOUR LOGO FOR EASTER',\n",
       " 'Occupy wall st.  y u no get jobs!!!',\n",
       " 'Daft punk  y u no release another album',\n",
       " 'Roxy  y u no shower',\n",
       " 'internet people  y u call spelling \"Grammar\"']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_y_u_no['caption'])[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_u_no_orig = df_y_u_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption_to_topic_brace_yourselves.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     caption_to_topic \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nursulu_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nursulu_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Nursulu_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Nursulu_1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# with open('caption_to_topic_brace_yourselves.json', 'r') as file:\n",
    "#     caption_to_topic = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove the word \"TOPIC\" from captions, train Gemma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"/Users/nursulusagimbayeva/Downloads/BMW_intern_GenAI_coding_task/yelling_man.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'arafed man in a suit and tie with his arms open'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip2-opt-2.7b\"\n",
    "headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"cats.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bmw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
