{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\n",
    "\n",
    "### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Input:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  {}\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = dict()\n",
    "all_prompts['happy'] = {}\n",
    "all_prompts['happy']['examples'] = [\"Caption: 'POV: he noticed my new haircut', Emotion: happy\",\n",
    "    \"Caption: 'POV: you find $5 in your coat pocket from last winter', Emotion: happy\",\n",
    "    \"Caption: 'POV: my feet when I wear a fresh pair of socks', Emotion: happy\",\n",
    "    \"Caption: 'POV: Trump imposing new sanctions', Emotion: happy\",\n",
    "    \"Caption: 'POV: average politics enjoyer', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I learned I have tatar blood', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I hear about planned economy', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when I finally scratched that spot', Emotion: happy\",\n",
    "    \"Caption: 'POV: me when the cashier said 'Hello' back', Emotion: happy\",\n",
    "    \"Caption: 'POV: me and my homies after we all got the same weekend off', Emotion: happy\"]\n",
    "\n",
    "all_prompts['happy']['prompt'] = \"Generate a short meme caption that will accompany some happy image. Only generate one-sentence meme caption and nothing else. Don't repeat the examples, generate new meme caption!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = 'happy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short meme caption:\n",
      "\n",
      "\"POV: I just found a reason to procrastinate\""
     ]
    }
   ],
   "source": [
    "client = InferenceClient(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=\"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\",\n",
    ")\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": content.format(\n",
    "     all_prompts[sentiment]['prompt'], # instruction\n",
    "     all_prompts[sentiment]['examples'],\n",
    "     \"\")}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a new meme caption:\n",
      "\n",
      "POV: I just realized I can eat ice cream for breakfast, and no one can stop me"
     ]
    }
   ],
   "source": [
    "client = InferenceClient(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=\"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\",\n",
    ")\n",
    "\n",
    "for message in client.chat_completion(\n",
    "\tmessages=[{\"role\": \"user\", \"content\": content.format(\n",
    "     all_prompts[sentiment]['prompt'], # instruction\n",
    "     all_prompts[sentiment]['examples'],\n",
    "     \"\")}],\n",
    "\tmax_tokens=500,\n",
    "\tstream=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95 \n",
    "):\n",
    "    print(message.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"/Users/nursulusagimbayeva/Downloads/BMW_intern_GenAI_coding_task/yelling_man.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'arafed man in a suit and tie with his arms open'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip2-opt-2.7b\"\n",
    "headers = {\"Authorization\": \"Bearer hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"cats.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bmw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
